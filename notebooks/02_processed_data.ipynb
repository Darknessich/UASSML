{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3af3913f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "275cde8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"..\"\n",
    "input_path = f\"{root}/data/augmented\"\n",
    "output_path = f\"{root}/data/processed\"\n",
    "input_tables = [\"spraying_performance_x10\", \"droplet_deposition_x10\", \"coffee_science_x10\"]\n",
    "\n",
    "datasets = [pd.read_csv(f\"{input_path}/{name}.csv\") for name in input_tables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2988a91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_collapsed_columns(df, columns_to_expand):\n",
    "    df = df.copy()\n",
    "    for col in columns_to_expand:\n",
    "        if col in df.columns:\n",
    "            df[f\"{col}.min\"] = df[col]\n",
    "            df[f\"{col}.max\"] = df[col]\n",
    "            df.drop(columns=[col], inplace=True)\n",
    "    return df\n",
    "\n",
    "def unified_dataset(tables, expand_columns):\n",
    "    expanded_tables = [expand_collapsed_columns(df, expand_columns) for df in tables]\n",
    "    return pd.concat(expanded_tables, ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d04b14f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразование столбцов таких как \"experiment.weather.temperature\" в \"(--//--).min\" и \"(--//--).max\"\n",
    "collapsed_columns = [\n",
    "    \"experiment.weather.temperature\",\n",
    "    \"experiment.weather.humidity\",\n",
    "    \"experiment.weather.velocity\",\n",
    "]\n",
    "merged = unified_dataset(datasets, collapsed_columns)\n",
    "\n",
    "# Объединение таблиц с дополнением (None) если столбцы/значения отсутствуют\n",
    "merged.to_csv(f\"{output_path}/merged.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4b1b6a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>null_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>plant.phenotypes.leaf_area</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>plant.phenotypes.diameter</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>plant.phenotypes.orthotropic_branch_node_number</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>plant.phenotypes.orthotropic_branch_length</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>plant.phenotypes.plagiotropic_node_distance</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>plant.phenotypes.plagiotropic_node_number</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>plant.genotype</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>experiment.params.flow_rate</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>model.positioning_mode</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>experiment.params.atomization_diameter</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>plant.phenotypes.height</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>model.weight</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>experiment.results.coverage.max</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>model.water_pump.number</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>model.water_pump.flow_rate</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>model.particle_diameter.max</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>model.particle_diameter.min</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>model.rotors.power</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>experiment.results.droplet_size.max</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>model.water_pump.type</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>model.swath_width.max</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>model.swath_width.min</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>model.dimensions.height</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>model.dimensions.width</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>model.dimensions.length</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>plant.cultivar</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>experiment.results.droplet_size.value</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>experiment.results.droplet_size.CV</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             column  null_count\n",
       "45                       plant.phenotypes.leaf_area         330\n",
       "44                        plant.phenotypes.diameter         330\n",
       "43  plant.phenotypes.orthotropic_branch_node_number         330\n",
       "42       plant.phenotypes.orthotropic_branch_length         330\n",
       "41      plant.phenotypes.plagiotropic_node_distance         330\n",
       "40        plant.phenotypes.plagiotropic_node_number         330\n",
       "39                                   plant.genotype         330\n",
       "38                      experiment.params.flow_rate         330\n",
       "37                           model.positioning_mode         330\n",
       "29           experiment.params.atomization_diameter         280\n",
       "36                          plant.phenotypes.height         240\n",
       "3                                      model.weight         180\n",
       "31                  experiment.results.coverage.max         180\n",
       "18                          model.water_pump.number         180\n",
       "17                       model.water_pump.flow_rate         180\n",
       "13                      model.particle_diameter.max         180\n",
       "12                      model.particle_diameter.min         180\n",
       "8                                model.rotors.power         180\n",
       "34              experiment.results.droplet_size.max          90\n",
       "16                            model.water_pump.type          90\n",
       "15                            model.swath_width.max          90\n",
       "14                            model.swath_width.min          90\n",
       "6                           model.dimensions.height          90\n",
       "5                            model.dimensions.width          90\n",
       "4                           model.dimensions.length          90\n",
       "1                                    plant.cultivar          90\n",
       "33            experiment.results.droplet_size.value          60\n",
       "35               experiment.results.droplet_size.CV          60"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Анализ столбцов с нулевыми значениями\n",
    "\n",
    "nulls = merged.isnull().sum().reset_index()\n",
    "nulls.columns = ['column', 'null_count']\n",
    "nulls_nonzero = nulls[nulls['null_count'] != 0]\n",
    "nulls_sorted = nulls_nonzero.sort_values(by='null_count', ascending=False)\n",
    "nulls_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a77d38d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_targets(df):\n",
    "    base_features = [col for col in df.columns if not col.startswith('experiment.results.')]\n",
    "    \n",
    "    df_cov = df[base_features + ['experiment.results.coverage.value']].copy()\n",
    "    df_cov = df_cov.dropna(subset=['experiment.results.coverage.value'])\n",
    "\n",
    "    df_drop = df[base_features + ['experiment.results.droplet_size.value']].copy()\n",
    "    df_drop = df_drop.dropna(subset=['experiment.results.droplet_size.value'])\n",
    "\n",
    "    return df_cov, df_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "941468cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заменим отсутствующие значения в atomization_diameter на \"off\"\n",
    "merged[\"experiment.params.atomization_diameter\"] = merged[\"experiment.params.atomization_diameter\"].fillna(\"off\")\n",
    "# Убираем колонку по которой можно точно идентифицировать среднее значение\n",
    "merged = merged.drop(\"experiment.name\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0519fe12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost shapes:\n",
      "Full: (420, 45)\n",
      "Coverage: (420, 40)\n",
      "Droplet size: (360, 40)\n"
     ]
    }
   ],
   "source": [
    "# Категориальные признаки, в которых NaN — отсутствие свойства. Для CatBoost оставляем как есть\n",
    "catboost_full = merged.copy()\n",
    "catboost_coverage, catboost_droplet_size = split_targets(catboost_full)\n",
    "catboost_full.to_csv(f\"{output_path}/catboost/full.csv\", index=False)\n",
    "catboost_coverage.to_csv(f\"{output_path}/catboost/coverage.csv\", index=False)\n",
    "catboost_droplet_size.to_csv(f\"{output_path}/catboost/droplet_size.csv\", index=False)\n",
    "\n",
    "print(\"CatBoost shapes:\")\n",
    "print(f\"Full: {catboost_full.shape}\")\n",
    "print(f\"Coverage: {catboost_coverage.shape}\")\n",
    "print(f\"Droplet size: {catboost_droplet_size.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d4db1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для остальных моделей — удалим все столбцы, содержащие хотя бы один NaN (кроме experiment.results.*)\n",
    "columns_to_keep = [col for col in merged.columns if col.startswith(\"experiment.results.\")]\n",
    "non_result_cols = [col for col in merged.columns if not col.startswith(\"experiment.results.\") and merged[col].isnull().sum() == 0]\n",
    "not_null_data = merged[columns_to_keep + non_result_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26c43cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost/GBR/FR shapes:\n",
      "Full: (420, 33)\n",
      "Coverage: (420, 28)\n",
      "Droplet size: (360, 28)\n"
     ]
    }
   ],
   "source": [
    "# Кодируем категориальные признаки и сохраняем отображение\n",
    "\n",
    "# Определим категориальные признаки\n",
    "category_cols = not_null_data.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Создание и обучение OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "encoded_array = ohe.fit_transform(not_null_data[category_cols])\n",
    "encoded_feature_names = ohe.get_feature_names_out(category_cols)\n",
    "\n",
    "# Создание DataFrame с закодированными признаками\n",
    "encoded_data = pd.DataFrame(encoded_array, columns=encoded_feature_names, index=not_null_data.index)\n",
    "\n",
    "# Объединение с остальными признаками\n",
    "numerical_data = not_null_data.drop(columns=category_cols)\n",
    "encoded_full = pd.concat([numerical_data, encoded_data], axis=1)\n",
    "encoded_coverage, encoded_droplet_size = split_targets(encoded_full)\n",
    "\n",
    "# Сохранение закодированного датафрейма\n",
    "encoded_full.to_csv(f\"{output_path}/encoded/full.csv\", index=False)\n",
    "encoded_coverage.to_csv(f\"{output_path}/encoded/coverage.csv\", index=False)\n",
    "encoded_droplet_size.to_csv(f\"{output_path}/encoded/droplet_size.csv\", index=False)\n",
    "\n",
    "# Сохраняем энкодер для обратного преобразования\n",
    "joblib.dump(ohe, f\"{output_path}/encoded/ohe_encoder.joblib\")\n",
    "\n",
    "print(\"XGBoost/GBR/FR shapes:\")\n",
    "print(f\"Full: {encoded_full.shape}\")\n",
    "print(f\"Coverage: {encoded_coverage.shape}\")\n",
    "print(f\"Droplet size: {encoded_droplet_size.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "769ce497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRV/MLR shapes:\n",
      "Full: (420, 33)\n",
      "Coverage: (420, 28)\n",
      "Droplet size: (360, 28)\n"
     ]
    }
   ],
   "source": [
    "# Масштабируем числовые признаки и сохраняем отображение\n",
    "\n",
    "# Найдём бинарные признаки (0 и 1), в частности категориальные\n",
    "binary_cols = [col for col in encoded_full.columns\n",
    "               if encoded_full[col].dropna().nunique() <= 2 and\n",
    "               set(encoded_full[col].dropna().unique()).issubset({0, 1})]\n",
    "\n",
    "# Остальные — непрерывные числовые\n",
    "num_cols = [col for col in encoded_full.columns if col not in binary_cols]\n",
    "\n",
    "# Масштабируем числовые признаки\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(encoded_full[num_cols])\n",
    "\n",
    "# Объединяем обратно с категориальными признаками\n",
    "binary_data = encoded_full[binary_cols]\n",
    "scaled_numeric = pd.DataFrame(scaled_data, columns=num_cols, index=encoded_full.index)\n",
    "scaled_full = pd.concat([scaled_numeric, binary_data], axis=1)\n",
    "scaled_coverage, scaled_droplet_size = split_targets(scaled_full)\n",
    "\n",
    "# Сохранение масштабированного датафрейма\n",
    "scaled_full.to_csv(f\"{output_path}/scaled/full.csv\", index=False)\n",
    "scaled_coverage.to_csv(f\"{output_path}/scaled/coverage.csv\", index=False)\n",
    "scaled_droplet_size.to_csv(f\"{output_path}/scaled/droplet_size.csv\", index=False)\n",
    "\n",
    "# Сохраняем scaler для будущего восстановления\n",
    "joblib.dump(scaler, f\"{output_path}/scaled/std_scaler.joblib\")\n",
    "\n",
    "print(\"SRV/MLR shapes:\")\n",
    "print(f\"Full: {scaled_full.shape}\")\n",
    "print(f\"Coverage: {scaled_coverage.shape}\")\n",
    "print(f\"Droplet size: {scaled_droplet_size.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
